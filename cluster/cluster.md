聚类算法属于无监督学习，即只给样本不给所属分类。用的比较少，辅助作用。如K-means聚类，层次聚类，混合高斯模型

学习内容：
	原理：定义，损失函数，步骤与结果判定
	应用注意点

聚类算法
1.用于发现共同的群体
2.试图探索和发现一定的模式（邮件聚类，用户购买模式等）
3.有时候作为监督学习中稀疏特征的预处理


聚类只能依靠特征间的相似度来划分，相似度的大小可以依据距离的远近，要把所有样本转化为向量，向量的距离有欧式距离等



---------------------------------------------------------------------------------------------------------------------------------
K-means聚类
输入：input1:N个样本{x1,x2,,,xn}
	  input2:拟定的额聚类个数K
初始化：
	1.随机初始化K个D维的向量
	2.选取K个样本点作为聚类的中心（初始样本中心）

迭代直至收敛：
	1.聚类中心点不再变化
	2.样本点到其聚类中心点的距离之和不再有较大变化。

损失函数：样本点到其聚类中心点的距离之和

最小化损失函数： 这个过程是个NP/无解问题，因为这个损失函数是个非凸函数，所以只能取到局部最低点。

那怎么办呢？
这个算法是初始聚类中心敏感的，怎么缓解？十次迭代，K-means++,选取多个初始点进行聚类


K的取值？肘点法，选取不同的K值，画出损失函数曲线，拐点即为K的取值，选取肘点值

局限性：
	1，属于硬聚类
	2，对异常点的免疫力很差，可以通过调整（比如中心不直接取均值，而是找离均值最近的样本点代替）
	3，对于团状的数据点集处理的好，对于带状等非凸形状不太好





------------------------------------------------------------------------------------------------------------------------------
层次聚类
K-means聚类里的K很难确定，有没有不用K的聚类算法，有！

补充：已知聚类，据称两个族，怎么球两个族的距离呢？最小距离链接发，最大距离链接发，平均距离链接法
由底部到顶部，不同时刻（不同步骤）根据族之间的距离再进性聚类，直到最后成为一个聚类
由顶部到底部，看一整个族里，哪个最不接近，踢出去，最后直到单一的族



-------------------------------------------------------------------------------------------------------------------------------
高斯混合模型Gaussion     GMM
给定一个均值，一个方差进行分布，高斯分布的宽度，高度受u,lamada影响
混合高斯Gassion Mixture：多个高斯分布区拟合，每个高斯有权重，概率值加权

假设一直样本容量N个，分类K个，知道



