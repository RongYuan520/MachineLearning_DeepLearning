{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用CNN实现手写数字识别\n",
    "输入是[28,28,1]\n",
    "\n",
    "conv1:[28,28,32](filter:[5,5,1],size=32,padding=same,strides=[1,1])\n",
    "max_pool1:[14,14,32](ksize=[2,2],strides=[2,2])\n",
    "\n",
    "conv2:[14,14,64](filter:[5,5,32],size=64,padding=same,strides=[1,1])\n",
    "max_pool2:[7,7,64](ksize=[2,2],strides=[2,2])\n",
    "\n",
    "flat:[7*7*64]\n",
    "    w1=[7*7*64,1024]\n",
    "fc1:[1024]\n",
    "    w2=[1024,10]\n",
    "fc2:[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1，数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(55000, 784) (55000, 10)\n",
      "(10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)\n",
    "\n",
    "print(mnist.train.images.shape,mnist.train.labels.shape)\n",
    "print(mnist.test.images.shape,mnist.test.labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2,准备好placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "x = tf.placeholder(tf.float32,[batch_size,784],name=\"x\")\n",
    "x_image = tf.reshape(x,[-1,28,28,1])\n",
    "y_ = tf.placeholder(tf.float32,[batch_size,10],name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3,初始化参数/权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_conv1 = tf.Variable(tf.random_normal([5,5,1,32]),name=\"w_conv1\")\n",
    "b_conv1 = tf.Variable(tf.zeros([32]),name=\"b_conv1\")\n",
    "\n",
    "\n",
    "w_conv2 = tf.Variable(tf.random_normal([5,5,32,64]),name=\"w_conv2\")\n",
    "b_conv2 = tf.Variable(tf.zeros([64]),name=\"b_conv2\")\n",
    "\n",
    "w_fc1 = tf.Variable(tf.random_normal([7*7*64,1024]),name=\"w_fc1\")\n",
    "b_fc1 = tf.Variable(tf.zeros([1024]),name=\"b_fc1\")\n",
    "\n",
    "w_fc2 = tf.Variable(tf.random_normal([1024,10]),name=\"w_fc2\")\n",
    "b_fc2 = tf.Variable(tf.zeros([10]),name=\"b_fc2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4,拿到每个类别的score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(tf.nn.conv2d(x_image,w_conv1,strides=[1,1,1,1],padding=\"SAME\") + b_conv1)\n",
    "h_pool1 = tf.nn.max_pool(h_conv1,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
    "\n",
    "h_conv2 = tf.nn.relu(tf.nn.conv2d(h_pool1,w_conv2,strides=[1,1,1,1],padding=\"SAME\") + b_conv2)\n",
    "h_pool2 = tf.nn.max_pool(h_conv2,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64])\n",
    "\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,w_fc1)+b_fc1)\n",
    "h_fc2 = tf.matmul(h_fc1,w_fc2)+b_fc2\n",
    "\n",
    "logits = h_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5,计算多分类的softmax的loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#交叉熵损失\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = y_,name=\"loss\")\n",
    "#求平均值\n",
    "loss = tf.reduce_mean(entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6,准备好optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7,在session里执行graph里定义的运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0:637876.7300872803\n",
      "epoch 1:23149.32145881653\n",
      "epoch 2:10718.248847007751\n",
      "epoch 3:5122.296646356583\n",
      "epoch 4:3065.6760714659936\n",
      "epoch 5:2026.704195142258\n",
      "epoch 6:2271.2985424995422\n",
      "epoch 7:2316.3909103538754\n",
      "epoch 8:2207.657495206543\n",
      "epoch 9:1601.6332616149448\n",
      "epoch 10:1635.1320364382118\n",
      "epoch 11:2306.3250555992126\n",
      "epoch 12:2419.971252501011\n",
      "epoch 13:2081.805906406602\n",
      "epoch 14:1541.8159923991186\n",
      "epoch 15:1791.374420169741\n",
      "epoch 16:2176.9552107096715\n",
      "epoch 17:2349.740435196326\n",
      "epoch 18:2136.1664056777954\n",
      "epoch 19:1925.0080615188926\n",
      "epoch 20:1529.6951380063547\n",
      "epoch 21:1941.0337077324878\n",
      "epoch 22:1590.7963467091322\n",
      "epoch 23:2475.137214422226\n",
      "epoch 24:1931.4243476688862\n",
      "epoch 25:1495.7468738276511\n",
      "epoch 26:1531.10822564736\n",
      "epoch 27:1534.4193782806396\n",
      "epoch 28:1503.5942910909653\n",
      "epoch 29:1548.0174161139876\n",
      "optimizer finished\n",
      "accuracy 0.9947\n"
     ]
    }
   ],
   "source": [
    "f = open(\"./_mnist_cnn.log\",'a') \n",
    "n_epoch = 30\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter(\"./graphs/logistic_rec\",sess.graph)\n",
    "    sess.run(init)\n",
    "    n_batch = int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(n_epoch):\n",
    "        total_loss = 0\n",
    "        for _ in range(n_batch):\n",
    "            x_batch,y_batch = mnist.train.next_batch(batch_size)\n",
    "            _,loss_batch = sess.run([optimizer,loss],feed_dict={x:x_batch,y_:y_batch})\n",
    "            total_loss += loss_batch\n",
    "        print(\"epoch {0}:{1}\".format(i,total_loss))\n",
    "        f.write(\"epoch {0}:{1}\".format(i,total_loss))\n",
    "        f.write(\"\\n\")\n",
    "    print(\"optimizer finished\")\n",
    "    f.write(\"optimizer finished\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    #测试模型\n",
    "    preds = tf.nn.softmax(logits)\n",
    "    correct_preds = tf.equal(tf.argmax(preds,1),tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_sum(tf.cast(correct_preds,tf.float32))\n",
    "    \n",
    "    n_batch = int(mnist.test.num_examples/batch_size)\n",
    "    total_correct_preds = 0\n",
    "    \n",
    "    for i in range(n_batch):\n",
    "        x_batch,y_batch = mnist.train.next_batch(batch_size)\n",
    "        accuracy_batch = sess.run([accuracy],feed_dict={x:x_batch,y_:y_batch})\n",
    "        total_correct_preds += accuracy_batch[0]\n",
    "    print(\"accuracy {0}\".format(total_correct_preds/mnist.test.num_examples))\n",
    "    f.write(\"accuracy {0}\".format(total_correct_preds/mnist.test.num_examples))\n",
    "    f.close()\n",
    "    writer.close()\n",
    "   \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
