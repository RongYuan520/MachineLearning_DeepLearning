{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用三层神经网络实现手写数字识别\n",
    "输入是784\n",
    "      W1=[784,256]\n",
    "layer1  256\n",
    "      W2=[256,256]\n",
    "layer2  256\n",
    "      W3=[256,10]\n",
    "输出是10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1，数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(55000, 784) (55000, 10)\n",
      "(10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)\n",
    "\n",
    "print(mnist.train.images.shape,mnist.train.labels.shape)\n",
    "print(mnist.test.images.shape,mnist.test.labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2,准备好placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 126\n",
    "x = tf.placeholder(tf.float32,[batch_size,784],name=\"x\")\n",
    "y_ = tf.placeholder(tf.float32,[batch_size,10],name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3,初始化参数/权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = 256\n",
    "\n",
    "hidden2 = 256\n",
    "\n",
    "classes = 10\n",
    "\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4,拿到每个类别的score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"fc_1\"):\n",
    "    w1 = tf.Variable(tf.random_normal([784,hidden1]),name=\"w1\")\n",
    "    b1 = tf.Variable(tf.zeros([hidden1]),name=\"b1\")\n",
    "    logits = tf.matmul(x,w1) + b1\n",
    "    logits = tf.nn.relu(logits,name=\"relu\")\n",
    "    \n",
    "with tf.variable_scope(\"dropout\"):\n",
    "    w2 = tf.Variable(tf.random_normal([hidden1,hidden2]),name=\"w2\")\n",
    "    b2 = tf.Variable(tf.zeros([hidden2]),name=\"b2\")\n",
    "    logits = tf.nn.dropout(logits,keep_prob)\n",
    "\n",
    "with tf.variable_scope(\"fc_2\"):\n",
    "    w3 = tf.Variable(tf.random_normal([hidden2,classes]),name=\"w3\")\n",
    "    b3 = tf.Variable(tf.zeros([classes]),name=\"b3\")\n",
    "    logits = tf.matmul(logits,w2) + b2\n",
    "    logits = tf.nn.relu(logits,name=\"relu\")\n",
    "    \n",
    "with tf.variable_scope(\"output\"):\n",
    "    logits = tf.matmul(logits,w3) + b3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5,计算多分类的softmax的loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#交叉熵损失\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = y_,name=\"loss\")\n",
    "#求平均值\n",
    "loss = tf.reduce_mean(entropy)\n",
    "loss_summary = tf.summary.scalar(\"my_loss\",loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6,准备好optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7,在session里执行graph里定义的运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0:32263.974585056305\n",
      "epoch 1:5613.664098978043\n",
      "epoch 2:2449.860861301422\n",
      "epoch 3:1224.066454231739\n",
      "epoch 4:748.3581049144268\n",
      "epoch 5:600.3050388395786\n",
      "epoch 6:500.15025421977043\n",
      "epoch 7:455.4277083873749\n",
      "epoch 8:439.87804558873177\n",
      "epoch 9:407.3439503312111\n",
      "epoch 10:388.59208285808563\n",
      "epoch 11:406.6936429440975\n",
      "epoch 12:396.4006362259388\n",
      "epoch 13:384.2311804294586\n",
      "epoch 14:390.69986352324486\n",
      "epoch 15:370.33665123581886\n",
      "epoch 16:346.89420452713966\n",
      "epoch 17:345.013072937727\n",
      "epoch 18:338.0301823914051\n",
      "epoch 19:317.61170426011086\n",
      "epoch 20:322.8593774139881\n",
      "epoch 21:321.27311313152313\n",
      "epoch 22:293.5258673131466\n",
      "epoch 23:269.31469586491585\n",
      "epoch 24:261.0479240119457\n",
      "epoch 25:277.50244414806366\n",
      "epoch 26:249.17410688102245\n",
      "epoch 27:251.14440834522247\n",
      "epoch 28:224.36869294941425\n",
      "epoch 29:212.07960914075375\n",
      "optimizer finished\n",
      "accuracy 0.9102\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 30\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter(\"./graphs/logistic_mul\",sess.graph)\n",
    "    sess.run(init)\n",
    "    n_batch = int(mnist.train.num_examples/batch_size)\n",
    "    \n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    \n",
    "    for i in range(n_epoch):\n",
    "        total_loss = 0\n",
    "        for j in range(n_batch):\n",
    "            x_batch,y_batch = mnist.train.next_batch(batch_size)\n",
    "            _,loss_batch,summary_loss = sess.run([optimizer,loss,merged_summary],feed_dict={x:x_batch,y_:y_batch,keep_prob:0.75})\n",
    "            total_loss += loss_batch\n",
    "            writer.add_summary(summary_loss)\n",
    "        print(\"epoch {0}:{1}\".format(i,total_loss))\n",
    "    print(\"optimizer finished\")\n",
    "    \n",
    "    #测试模型\n",
    "    preds = tf.nn.softmax(logits)\n",
    "    correct_preds = tf.equal(tf.argmax(preds,1),tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_sum(tf.cast(correct_preds,tf.float32))\n",
    "    \n",
    "    n_batch = int(mnist.test.num_examples/batch_size)\n",
    "    total_correct_preds = 0\n",
    "    \n",
    "    for i in range(n_batch):\n",
    "        x_batch,y_batch = mnist.train.next_batch(batch_size)\n",
    "        accuracy_batch = sess.run([accuracy],feed_dict={x:x_batch,y_:y_batch,keep_prob:1.0})\n",
    "        total_correct_preds += accuracy_batch[0]\n",
    "    print(\"accuracy {0}\".format(total_correct_preds/mnist.test.num_examples))\n",
    "    \n",
    "    writer.close()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
